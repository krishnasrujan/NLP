{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2882,
     "status": "ok",
     "timestamp": 1606296238504,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "lfIJQz-1ttHQ"
   },
   "outputs": [],
   "source": [
    "# !pip install -U spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7245,
     "status": "ok",
     "timestamp": 1606296273334,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "d_y1Qn_attHR",
    "outputId": "202371d9-2a4b-4865-a37e-5551ec588992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.47.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.2.0.post20200714)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.11.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.47.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\srujan\\anaconda\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2196,
     "status": "ok",
     "timestamp": 1606296284141,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "AvLT0k72ttHS",
    "outputId": "acd94f14-8520-4f6f-cbd9-60b1513834b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x115c54dbfc8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load small english model: https://spacy.io/models\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1383,
     "status": "ok",
     "timestamp": 1606296291272,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "i56rmh2MttHT",
    "outputId": "eb849224-7500-4be9-84f6-97c7bcb780bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse text through the `nlp` model\n",
    "my_text = \"\"\"The economic situation of the country is on edge , as the stock market crashed causing loss of millions.\\\n",
    "Citizens who had their main investment in the share-market are facing a great loss. Many companies might lay off\\\n",
    "thousands of people to reduce labor cost\"\"\"\n",
    "\n",
    "my_doc = nlp(my_text)\n",
    "type(my_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus NNP learning nsubj\n",
      "is VBZ learning aux\n",
      "learning VBG learning ROOT\n",
      "piano NN learning dobj\n"
     ]
    }
   ],
   "source": [
    "piano_text = 'Gus is learning piano'\n",
    "piano_doc = nlp(piano_text)\n",
    "for token in piano_doc:\n",
    "     print (token.text, token.tag_, token.head.text, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'displacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a0f00935f76c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpiano_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dep'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'displacy' is not defined"
     ]
    }
   ],
   "source": [
    "displacy.serve(piano_doc, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdYTyegmttHT"
   },
   "source": [
    "## Tokenization with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1720,
     "status": "ok",
     "timestamp": 1606296328147,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "_Adi3azettHT",
    "outputId": "554e4c1a-01a9-4fbc-c36a-8f21215a0dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "economic\n",
      "situation\n",
      "of\n",
      "the\n",
      "country\n",
      "is\n",
      "on\n",
      "edge\n",
      ",\n",
      "as\n",
      "the\n",
      "stock\n",
      "market\n",
      "crashed\n",
      "causing\n",
      "loss\n",
      "of\n",
      "millions\n",
      ".\n",
      "Citizens\n",
      "who\n",
      "had\n",
      "their\n",
      "main\n",
      "investment\n",
      "in\n",
      "the\n",
      "share\n",
      "-\n",
      "market\n",
      "are\n",
      "facing\n",
      "a\n",
      "great\n",
      "loss\n",
      ".\n",
      "Many\n",
      "companies\n",
      "might\n",
      "lay\n",
      "offthousands\n",
      "of\n",
      "people\n",
      "to\n",
      "reduce\n",
      "labor\n",
      "cost\n"
     ]
    }
   ],
   "source": [
    "# Printing the tokens of a doc\n",
    "for token in my_doc:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nl6ArGRottHT"
   },
   "source": [
    "## Text-Preprocessing with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1408,
     "status": "ok",
     "timestamp": 1606296358466,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "hLOo5V3SttHT",
    "outputId": "296382dd-2da9-40f6-93e2-0bdb2f96eeda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -- True --- False\n",
      "economic -- False --- False\n",
      "situation -- False --- False\n",
      "of -- True --- False\n",
      "the -- True --- False\n",
      "country -- False --- False\n",
      "is -- True --- False\n",
      "on -- True --- False\n",
      "edge -- False --- False\n",
      ", -- False --- True\n",
      "as -- True --- False\n",
      "the -- True --- False\n",
      "stock -- False --- False\n",
      "market -- False --- False\n",
      "crashed -- False --- False\n",
      "causing -- False --- False\n",
      "loss -- False --- False\n",
      "of -- True --- False\n",
      "millions -- False --- False\n",
      ". -- False --- True\n",
      "Citizens -- False --- False\n",
      "who -- True --- False\n",
      "had -- True --- False\n",
      "their -- True --- False\n",
      "main -- False --- False\n",
      "investment -- False --- False\n",
      "in -- True --- False\n",
      "the -- True --- False\n",
      "share -- False --- False\n",
      "- -- False --- True\n",
      "market -- False --- False\n",
      "are -- True --- False\n",
      "facing -- False --- False\n",
      "a -- True --- False\n",
      "great -- False --- False\n",
      "loss -- False --- False\n",
      ". -- False --- True\n",
      "Many -- True --- False\n",
      "companies -- False --- False\n",
      "might -- True --- False\n",
      "lay -- False --- False\n",
      "offthousands -- False --- False\n",
      "of -- True --- False\n",
      "people -- False --- False\n",
      "to -- True --- False\n",
      "reduce -- False --- False\n",
      "labor -- False --- False\n",
      "cost -- False --- False\n"
     ]
    }
   ],
   "source": [
    "# Printing tokens and boolean values stored in different attributes\n",
    "for token in my_doc:\n",
    "    print(token.text,'--',token.is_stop,'---',token.is_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1424,
     "status": "ok",
     "timestamp": 1606296599394,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "tHar55yottHU",
    "outputId": "25bcef2c-aabb-48e1-8861-4c2805add2cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "economic\n",
      "situation\n",
      "country\n",
      "edge\n",
      "stock\n",
      "market\n",
      "crashed\n",
      "causing\n",
      "loss\n",
      "millions\n",
      "Citizens\n",
      "main\n",
      "investment\n",
      "share\n",
      "market\n",
      "facing\n",
      "great\n",
      "loss\n",
      "companies\n",
      "lay\n",
      "offthousands\n",
      "people\n",
      "reduce\n",
      "labor\n",
      "cost\n"
     ]
    }
   ],
   "source": [
    "# Removing StopWords and punctuations\n",
    "my_doc_cleaned = [token for token in my_doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "for token in my_doc_cleaned:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1893,
     "status": "ok",
     "timestamp": 1606296644816,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "TgjXSdEwttHU",
    "outputId": "4cc75119-d262-4185-ecca-3e79610ab720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PreProcessing n_Tokens:  1626\n",
      "After PreProcessing n_Tokens:  744\n"
     ]
    }
   ],
   "source": [
    "# Reading a huge text data on robotics into a spacy doc\n",
    "robotics_data= \"\"\"Robotics is an interdisciplinary research area at the interface of computer science and engineering. Robotics involvesdesign, construction, operation, and use of robots. The goal of robotics is to design intelligent machines that can help and assist humans in their day-to-day lives and keep everyone safe. Robotics draws on the achievement of information engineering, computer engineering, mechanical engineering, electronic engineering and others.Robotics develops machines that can substitute for humans and replicate human actions. Robots can be used in many situations and for lots of purposes, but today many are used in dangerous environments(including inspection of radioactive materials, bomb detection and deactivation), manufacturing processes, or where humans cannot survive (e.g. in space, underwater, in high heat, and clean up and containment of hazardousmaterials and radiation). Robots can take on any form but some are made to resemble humans in appearance. This is said to help in the acceptance of a robot in \n",
    "certain replicative behaviors usually performed by people. Such robots attempt to replicate walking, lifting, speech, cognition, or any other human activity. Many of todays robots are inspired by nature, contributing to the field of bio-inspired \n",
    "robotics.The concept of creating machines that can operate autonomously dates back to classical times, but research into the functionality and potential uses of robots did not grow substantially until the 20th century. Throughout history, it has been frequently assumed by various scholars, inventors, engineers, and technicians that robots will one day be able to mimic human behavior and manage tasks in a human-like fashion. Today, robotics is a rapidly growing field, as technological advances continue; researching, designing, and building new robots serve various practical purposes, whether domestically, commercially, or militarily. Many robots are built to do jobs that are hazardous to people, such as defusing bombs, finding survivors in unstable ruins, and exploring mines and shipwrecks. Robotics is also used in STEM (science, technology, engineering, and mathematics) as a teaching aid. The advent of nanorobots, microscopic robots that can be injected into the human body, could revolutionize medicine and human health.Robotics is a branch of engineering that involves the conception, design, manufacture, and operation of robots. This field overlaps with computer engineering, computer science (especially artificial intelligence), electronics, mechatronics, nanotechnology and bioengineering.The word robotics was derived from the word robot, which was introduced to the public by Czech writer Karel Capek in his play R.U.R. (Rossums Universal Robots), whichwas published in 1920. The word robot comes from the Slavic word robota, which means slave/servant. The play begins in a factory that makes artificial people called robots, creatures who can be mistaken for humans – very similar to the modern ideas of androids. Karel Capek himself did not coin the word. He wrote a short letter in reference to an etymology in the \n",
    "Oxford English Dictionary in which he named his brother Josef Capek as its actual \n",
    "originator.According to the Oxford English Dictionary, the word robotics was first \n",
    "used in print by Isaac Asimov, in his science fiction short story \"Liar!\", \n",
    "published in May 1941 in Astounding Science Fiction. Asimov was unaware that he \n",
    "was coining the term  since the science and technology of electrical devices is \n",
    "electronics, he assumed robotics already referred to the science and technology \n",
    "of robots. In some of Asimovs other works, he states that the first use of the \n",
    "word robotics was in his short story Runaround (Astounding Science Fiction, March \n",
    "1942) where he introduced his concept of The Three Laws of Robotics. However, \n",
    "the original publication of \"Liar!\" predates that of \"Runaround\" by ten months, \n",
    "so the former is generally cited as the words origin.There are many types of robots; \n",
    "they are used in many different environments and for many different uses. Although \n",
    "being very diverse in application and form, they all share three basic similarities \n",
    "when it comes to their construction:Robots all have some kind of mechanical construction, a frame, form or shape designed to achieve a particular task. For example, a robot designed to travel across heavy dirt or mud, might use caterpillar tracks. The mechanical aspect is mostly the creators solution to completing the assigned task and dealing with the physics of the environment around it. Form follows function.Robots have electrical components which power and control the machinery. For example, the robot with caterpillar tracks would need some kind of power to move the tracker treads. That power comes in the form of electricity, which will have to travel through a wire and originate from a battery, a basic electrical circuit. Even petrol powered machines that get their power mainly from petrol still require an electric current to start the combustion process which is why most petrol powered machines like cars, have batteries. The electrical aspect of robots is used for movement (through motors), sensing (where electrical signals are used to measure things like heat, sound, position, and energy status) and operation (robots need some level of electrical energy supplied to their motors and sensors in order to activate and perform basic operations) All robots contain some level of computer programming code. A program is how a robot decides when or how to do something. In the caterpillar track example, a robot that needs to move across a muddy road may have the correct mechanical construction and receive the correct amount of power from its battery, but would not go anywhere without a program telling it to move. Programs are the core essence of a robot, it could have excellent mechanical and electrical construction, but if its program is poorly constructed its performance will be very poor (or it may not perform at all). There are three different types of robotic programs: remote control, artificial intelligence and hybrid. A robot with remote control programing has a preexisting set of commands that it will only perform if and when it receives a signal from a control source, typically a human being with a remote control. It is perhaps more appropriate to view devices controlled primarily by human commands as falling in the discipline of automation rather than robotics. Robots that use artificial intelligence interact with their environment on their own without a control source, and can determine reactions to objects and problems they encounter using their preexisting programming. Hybrid is a form of programming that incorporates both AI and RC functions.As more and more robots are designed for specific tasks this method of classification becomes more relevant. For example, many robots are designed for assembly work, which may not be readily adaptable for other applications. They are termed as \"assembly robots\". For seam welding, some suppliers provide complete welding systems with the robot i.e. the welding equipment along with other material handling facilities like turntables, etc. as an integrated unit. Such an integrated robotic system is called a \"welding robot\" even though its discrete manipulator unit could be adapted to a variety of tasks. Some robots are specifically designed for heavy load manipulation, and are labeled as \"heavy-duty robots\".one or two wheels. These can have certain advantages such as greater efficiency and reduced parts, as well as allowing a robot to navigate in confined places that a four-wheeled robot would not be able to.Two-wheeled balancing robots Balancing robots generally use a gyroscope to detect how much a robot is falling and then drive the wheels proportionally in the same direction, to counterbalance the fall at hundreds of times per second, based on the dynamics of an inverted pendulum.[71] Many different balancing robots have been designed.[72] While the Segway is not commonly thought of as a robot, it can be thought of as a component of a robot, when used as such Segway refer to them as RMP (Robotic Mobility Platform). An example of this use has been as NASA Robonaut that has been mounted on a Segway.One-wheeled balancing robots Main article: Self-balancing unicycle A one-wheeled balancing robot is an extension of a two-wheeled balancing robot so that it can move in any 2D direction using a round ball as its only wheel. Several one-wheeled balancing robots have been designed recently, such as Carnegie Mellon Universitys \"Ballbot\" that is the approximate height and width of a person, and Tohoku Gakuin University BallIP Because of the long, thin shape and ability to maneuver in tight spaces, they have the potential to function better than other robots in environments with people\n",
    "\"\"\"\n",
    "\n",
    "# Pass the Text to Model\n",
    "robotics_doc = nlp(robotics_data)\n",
    "\n",
    "print('Before PreProcessing n_Tokens: ', len(robotics_doc))\n",
    "\n",
    "# Removing stopwords and punctuation from the doc.\n",
    "robotics_doc=[token for token in robotics_doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "print('After PreProcessing n_Tokens: ', len(robotics_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btsaZ1-yttHU"
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1369,
     "status": "ok",
     "timestamp": 1606296939477,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "xhTpm5kSttHU",
    "outputId": "cd546321-0ade-43b5-ab8a-55f119793a74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n",
      "play\n",
      "play\n",
      ".\n",
      "like\n",
      "like\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing the tokens of a doc\n",
    "text='played plays playing. likes like'\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNNRFx9mttHU"
   },
   "source": [
    "## Lexical attributes of spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1354,
     "status": "ok",
     "timestamp": 1606297216442,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "NCaiYvyyttHU",
    "outputId": "0879f8ec-a654-4cb1-c9c4-b988b6277411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "text=' 2020 is far worse than 2009'\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "    if token.like_num:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kb7UiWtKttHU"
   },
   "source": [
    "## Question\n",
    "## Consider you have a text document about details of various employees.\n",
    "## What if you want all the emails of employees to send a common email ?\n",
    "employee_text=\"\"\" name : Koushiki age: 45 email : koushiki@gmail.com\n",
    "                 name : Gayathri age: 34 email: gayathri1999@gmail.com\n",
    "                 name : Ardra age: 60 email : ardra@gmail.com\n",
    "                 name : pratham parmar age: 15 email : parmar15@yahoo.com\n",
    "                 name : Shashank age: 54 email: shank@rediffmail.com\n",
    "                 name : Utkarsh age: 46 email :utkarsh@gmail.com\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPzwKMbRttHU"
   },
   "source": [
    "## Part of Speech analysis with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzxy5U8xttHU",
    "outputId": "6ed0a9bf-3756-4f84-fcc8-2a890f428f3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John ----  PROPN\n",
      "plays ----  VERB\n",
      "basketball ----  NOUN\n",
      ", ----  PUNCT\n",
      "if ----  SCONJ\n",
      "time ----  NOUN\n",
      "permits ----  VERB\n",
      ". ----  PUNCT\n",
      "He ----  PRON\n",
      "played ----  VERB\n",
      "in ----  ADP\n",
      "high ----  ADJ\n",
      "school ----  NOUN\n",
      "too ----  ADV\n",
      ". ----  PUNCT\n"
     ]
    }
   ],
   "source": [
    "# POS tagging using spaCy\n",
    "my_text='John plays basketball,if time permits. He played in high school too.'\n",
    "my_doc=nlp(my_text)\n",
    "for token in my_doc:\n",
    "  print(token.text,'---- ',token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lF-3MTfPttHV",
    "outputId": "5167392b-7a25-4945-fe90-7ef96e06e4f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subordinating conjunction'"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('SCONJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kt4F-wmPttHV",
    "outputId": "a7c2ec15-bfb8-4bbf-d0d3-0a2f8c17d20e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The junk values are..\n",
      "etc\n",
      "i.e.\n",
      "i.e.\n",
      "etc\n",
      "etc\n",
      "After removing junk\n",
      "[I, liked, the, movies, The, movie, had, good, direction,  , The, movie, was, amazing, \n",
      "            , The, movie, was, average, direction, was, not, bad, The, cinematography, was, nice, ., \n",
      "            , The, movie, was, a, bit, lengthy,  , otherwise, fantastic,  ]\n"
     ]
    }
   ],
   "source": [
    "# Raw text document\n",
    "raw_text=\"\"\"I liked the movies etc The movie had good direction  The movie was amazing i.e.\n",
    "            The movie was average direction was not bad The cinematography was nice. i.e.\n",
    "            The movie was a bit lengthy  otherwise fantastic  etc etc\"\"\"\n",
    "# Creating a spacy object\n",
    "raw_doc=nlp(raw_text)\n",
    "\n",
    "# Checking if POS tag is X and printing them\n",
    "print('The junk values are..')\n",
    "for token in raw_doc:\n",
    "    if token.pos_=='X':\n",
    "        print(token.text)\n",
    "\n",
    "print('After removing junk')\n",
    "# Removing the tokens whose POS tag is junk.\n",
    "clean_doc=[token for token in raw_doc if not token.pos_=='X']\n",
    "print(clean_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1R5bqGOttHV"
   },
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4s8n5SgttHV",
    "outputId": "658198fb-6970-4694-ff42-c6b5e70a697f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tony Stark, StarkEnterprises, Emily Clark, Microsoft, Manchester, Bible, French)\n",
      "Tony Stark ---  PERSON\n",
      "StarkEnterprises ---  ORG\n",
      "Emily Clark ---  PERSON\n",
      "Microsoft ---  ORG\n",
      "Manchester ---  GPE\n",
      "Bible ---  WORK_OF_ART\n",
      "French ---  NORP\n"
     ]
    }
   ],
   "source": [
    "# Preparing the spaCy document\n",
    "text='Tony Stark owns the company StarkEnterprises . Emily Clark works at Microsoft and lives in Manchester. She loves to read the Bible and learn French'\n",
    "doc=nlp(text)\n",
    "\n",
    "# Printing the named entities\n",
    "print(doc.ents)\n",
    "# Printing labels of entities.\n",
    "for entity in doc.ents:\n",
    "  print(entity.text,'--- ',entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtKWB2dTttHV",
    "outputId": "665c98a8-d564-406f-f40d-ef5cbee8fed9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tony Stark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " owns the company \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    StarkEnterprises\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " . \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Emily Clark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " works at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and lives in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Manchester\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". She loves to read the \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bible\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " and learn \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    French\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using displacy for visualizing NER\n",
    "from spacy import displacy\n",
    "displacy.render(doc,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPp782RmttHV"
   },
   "source": [
    "## Extracting brand names with Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgDSm-_sttHV"
   },
   "outputs": [],
   "source": [
    "mobile_industry_article=\"\"\" 30 Major mobile phone brands Compete in India – A Case Study of Success and Failures\n",
    "Is the Indian mobile market a terrible War Zone? We have more than 30 brands competing with each other. Let’s find out some insights about the world second-largest mobile bazaar.There is a massive invasion by Chinese mobile brands in India in the last four years. Some of the brands have been able to make a mark while others like Meizu, Coolpad, ZTE, and LeEco are a failure.On one side, there are brands like Sony or HTC that have quit from the Indian market on the other side we have new brands like Realme or iQOO entering the marketing in recent months.The mobile market is so competitive that some of the brands like Micromax, which had over 18% share back in 2014, now have less than 5%. Even the market leader Samsung with a 34% market share in 2014, now has a 21% share whereas Xiaomi has become a market leader. The battle is fierce and to sustain and scale-up is going to be very difficult for any new entrant.new comers in Indian Mobile MarketiQOO –They have recently (March 2020) launched the iQOO 3 in India with its first 5G phone – iQOO 3. The new brand is part of the Vivo or the BBK electronics group that also owns several other brands like Oppo, Oneplus and Realme.Realme – Realme launched the first-ever phone – Realme 1 in November 2018 and has quickly became a popular brand in India. The brand is one of the highest sellers in online space and even reached a 16% market share threatening Xiaomi’s dominance.iVoomi – In 2017, we have seen the entry of some new Chinese mobile brands likeiVoomi which focuses on the sub 10k price range, and is a popular online player. They have an association with Flipkart.Techno &amp; Infinix – Transsion Group’s Tecno and Infinix brands debuted in India in mid-2017 and are focusing on the low end and mid-range phones in the price range of Rs. 5000 to Rs. 12000.10.OR &amp; Lephone – 10.OR has a partnership with Amazon India and is an exclusive online brand with phones like 10.OR D, G and E. However, the brand is not very aggressive currently.Kult – Kult is another player who launched a very aggressively priced Kult Beyond mobile in 2017 and followed up by launching 2-3 more models.However, most of these new brands are finding it difficult to strengthen their footing in India. As big brands like Xiaomi leave no stone unturned to make things difficult.Also, it is worth noting that there is less Chinese players coming to India now. As either all the big brands have already set shop or burnt their hands and retreated to the homeland China.Chinese/ Global  Brands Which failed or are at the Verge of Failing in India?\n",
    "There are a lot more failures in the market than the success stories. Let’s first look at the failures and then we will also discuss why some brands were able to succeed in India.HTC – The biggest surprise this year for me was the failure of HTC in India. The brand has been in the country for many years, in fact, they were the first brand to launch Android mobiles. Finally HTC decided to call it a day in July 2018.LeEco – LeEco looked promising and even threatening to Xiaomi when it came to India. The company launched a series of new phones and smart TVs at affordable rates. Unfortunately, poor financial planning back home caused the brand to fail in India too.LG – The company seems to have lost focus and are doing poorly in all segments. While the budget and mid-range offering are uncompetitive, the high-end models are not preferred by buyers.Sony – Absurd pricing and lack of ability to understand the Indian buyers have caused Sony to shrink mobile operations in India. In the last 2 years, there are far fewer launches and hardly any promotions or hype around the new products.Meizu – Meizu is also a struggling brand in India and is going nowhere with the current strategy. There are hardly any popular mobiles nor a retail presence.ZTE – The company was aggressive till last year with several new phones launching under the Nubia banner, but with recent issues in the US, they have even lost the plot in India.Coolpad – I still remember the first meeting with Coolpad CEO in Mumbai when the brand started operations. There were big dreams and ambitions, but the company has not been able to deliver and keep up with the rivals in the last 1 year.Gionee – Gionee was doing well in the retail, but the infighting in the company and loss of focus from the Chinese parent company has made it a failure. The company is planning a comeback. However, we will have to wait and see when that happens.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-v4MFZOttHV",
    "outputId": "129c7aa9-029f-42fa-9ac9-f018cd5413b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meizu', 'Sony', 'Vivo', 'Xiaomi', 'Flipkart', 'Techno &amp', 'Infinix – Transsion Group', '12000.10.OR &amp', 'Lephone', 'Amazon India', 'Global  Brands', 'the Verge of Failing', 'Sony', 'Sony', 'Meizu', 'Meizu', 'Nubia']\n"
     ]
    }
   ],
   "source": [
    "# creating spacy doc\n",
    "mobile_doc=nlp(mobile_industry_article)\n",
    "\n",
    "# List to store name of mobile companies\n",
    "list_of_org=[]\n",
    "\n",
    "# Appending entities which havel the label 'ORG' to the list\n",
    "for entity in mobile_doc.ents:\n",
    "  if entity.label_=='ORG':\n",
    "    list_of_org.append(entity.text)\n",
    "\n",
    "print(list_of_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoheogDVttHV"
   },
   "source": [
    "## You come across many articles about theft and other crimes.\n",
    "## While using this for a case study, you might need to to avoid use of original names, companies and places. How can you do it ?\n",
    "\n",
    "## Write a function which will scan the text for named entities which have the labels PERSON , ORG and GPE. These tokens can be replaced by “UNKNOWN”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTIh1JLmttHV"
   },
   "source": [
    "## spaCy pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88ErasUFttHV",
    "outputId": "ff7029c6-cee5-4707-928e-79be04c11001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7VTdAdPttHV"
   },
   "source": [
    "## Adding components to pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxgoNAHJttHV",
    "outputId": "cfd0a91a-54e0-4493-8560-a1c15b37fdc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'textcat']\n"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe(nlp.create_pipe('textcat'))\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVqZTgj8ttHV",
    "outputId": "a5a5ec7e-4756-4803-84b1-09eef3786379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('textcat', <spacy.pipeline.pipes.TextCategorizer at 0x21724d52948>)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.remove_pipe(\"textcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXambVUdttHW",
    "outputId": "85474933-8ddc-4261-a193-fc167d89319d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cda0MT3ittHW"
   },
   "outputs": [],
   "source": [
    "## Creating custom pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4cJtBdDttHW",
    "outputId": "952aa4be-4913-4ab2-ca8b-5f0b9ebff863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'my_custom_component']\n",
      " The no of tokens in the document  21\n",
      "['ORG', 'GPE']\n"
     ]
    }
   ],
   "source": [
    "def my_custom_component(doc):\n",
    "    doc_length = len(doc)\n",
    "    print(' The no of tokens in the document ', doc_length)\n",
    "    named_entity=[token.label_ for token in doc.ents]\n",
    "    print(named_entity)\n",
    "    # Return the doc\n",
    "    return doc\n",
    "\n",
    "\n",
    "# Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add the component in the pipeline after ner\n",
    "nlp.add_pipe(my_custom_component, after='ner')\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Call the nlp object on your text\n",
    "doc = nlp(\" The Hindu Newspaper has increased the cost. I usually read the paper on my way to Delhi railway station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unhA1NCqttHW"
   },
   "source": [
    "## Coreference resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZyzabUnttHW"
   },
   "outputs": [],
   "source": [
    "import spacy, neuralcoref\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLJgkWoSttHW",
    "outputId": "d176b75d-937c-4bc4-ea46-ee01b6245120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[My sister: [My sister, She], a dog: [a dog, him]]\n"
     ]
    }
   ],
   "source": [
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "doc1 = nlp('My sister has a dog. She loves him.')\n",
    "print(doc1._.coref_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EN0beka5ttHW",
    "outputId": "372b56b2-5d2f-425e-8461-eac599680a22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Boston,)\n",
      "Boston: [Boston, that city]\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp('Angela lives in Boston. She is quite happy in that city.')\n",
    "print(doc2.ents)\n",
    "for ent in doc2.ents:\n",
    "    print(ent._.coref_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGDnEv8attHW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Spacy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
