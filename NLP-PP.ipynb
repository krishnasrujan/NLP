{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCa9Ibp-wUzv"
   },
   "source": [
    "# Read file in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 2698,
     "status": "error",
     "timestamp": 1606481480809,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "is3APce2wUzx",
    "outputId": "3e56de9b-9201-4867-99ad-d2d1d89f0c81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>This &lt;b&gt;product&lt;/b&gt; so far has not disappointe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "1  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "2  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "3  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "4  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "\n",
       "                                              review  \n",
       "0  This <b>product</b> so far has not disappointe...  \n",
       "1  great for beginner or experienced person. Boug...  \n",
       "2  Inexpensive tablet for him to use and learn on...  \n",
       "3  I've had my Fire HD 8 two weeks now and I love...  \n",
       "4  I bought this for my grand daughter when she c...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/Srujan/Documents/Datasets/amazon_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GCFMmJ-BwUz1",
    "outputId": "bee37f65-b092-470e-d685-a37d044432eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uEs1KP4RwUz2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've had my Fire HD 8 two weeks now and I love it. This tablet is a great value.We are Prime Members and that is where this tablet SHINES. I love being able to easily access all of the Prime content as well as movies you can download and watch laterThis has a 1280/800 screen which has some really nice look to it its nice and crisp and very bright infact it is brighter then the ipad pro costing $900 base model. The build on this fire is INSANELY AWESOME running at only 7.7mm thick and the smooth glossy feel on the back it is really amazing to hold its like the futuristic tab in ur hands.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IMFira0wUz2"
   },
   "source": [
    "# Removing HTML content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFfr5P4JwUz2"
   },
   "source": [
    "You get your most of data from web scrapping.\n",
    "Problem with that data is it contains tags, images, ads, etc which is of no use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O2qEcFp5wUz2"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text,'lxml')\n",
    "    html_free = soup.get_text()\n",
    "    return html_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9VX8Lq4xwUz2",
    "outputId": "25c2cc85-dfe2-4a74-ea4b-21b1708eb7f1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srujan\\Anaconda\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:421: MarkupResemblesLocatorWarning: \"https://www.amazon.com/dp/B01J2G4VBG/refcmcrrypprdttlsol4\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    This product so far has not disappointed. My c...\n",
       "1    great for beginner or experienced person. Boug...\n",
       "2    Inexpensive tablet for him to use and learn on...\n",
       "3    I've had my Fire HD 8 two weeks now and I love...\n",
       "4    I bought this for my grand daughter when she c...\n",
       "Name: review_html_removed, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']=df.review.astype('str')\n",
    "df['review_html_removed'] = df['review'].apply(remove_html);\n",
    "df.review_html_removed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDQx3Ro_wUz2"
   },
   "source": [
    "# Removing Contractions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MukVczywUz2"
   },
   "source": [
    "Data should be in standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iWpFPUOtwUz3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile(\"(ain't|aren't|can't|'cause|could've|couldn't|didn't|doesn't|don't|hadn't|hasn't|haven't|he'd|he'll|he's|how'd|how'd'y|how'll|how's|I'd|I'd've|I'll|I'll've|I'm|I've|i'd|i'd've|i'll|i'll've|i'm|i've|is)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\",\n",
    "                    \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \n",
    "                    \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \n",
    "                    \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \n",
    "                    \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \n",
    "                    \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\n",
    "                    \"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
    "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \n",
    "                    \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "                    \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
    "                    \"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
    "                    \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \n",
    "                    \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \n",
    "                    \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \n",
    "                    \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                    \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \n",
    "                    \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n",
    "                    \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                    \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \n",
    "                    \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \n",
    "                    \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                    \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \n",
    "                    \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \n",
    "                    \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                    \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n",
    "                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                    \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                    \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \n",
    "                    \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "def _get_contractions(contraction_dict):\n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict, contraction_re\n",
    "\n",
    "contractions, contractions_re = _get_contractions(contraction_dict)\n",
    "print(contractions_re)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "# Usage\n",
    "# replace_contractions(\"this's a text with contraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jg59_B1DwUz3",
    "outputId": "e1fc6cf9-bf0e-4cf1-bd08-89ded5957963"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This product so far has not disappointed. My c...\n",
       "1    great for beginner or experienced person. Boug...\n",
       "2    Inexpensive tablet for him to use and learn on...\n",
       "3    I have had my Fire HD 8 two weeks now and I lo...\n",
       "4    I bought this for my grand daughter when she c...\n",
       "Name: review_contractions_removed, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_contractions_removed'] = df['review_html_removed'].apply(replace_contractions)\n",
    "df.review_contractions_removed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFaizfT7wUz3"
   },
   "source": [
    "# Removing Punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMYxADcVwUz3"
   },
   "source": [
    "While processing text, punctuations don't play any important role so it is good practice to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1220,
     "status": "ok",
     "timestamp": 1606481591170,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "GTZlOqOBwUz3",
    "outputId": "526fa931-40f8-4bd5-9380-4b5ead7fd613"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1606481602285,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "fu4pNI3_wUz3"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation+('।')])    \n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "executionInfo": {
     "elapsed": 1121,
     "status": "error",
     "timestamp": 1606481605224,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "IeiIInZZwUz3",
    "outputId": "bcea608c-8751-414d-ab20-6a07244a7ecb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This product so far has not disappointed My ch...\n",
       "1    great for beginner or experienced person Bough...\n",
       "2    Inexpensive tablet for him to use and learn on...\n",
       "3    I have had my Fire HD 8 two weeks now and I lo...\n",
       "4    I bought this for my grand daughter when she c...\n",
       "Name: review_punct_removed, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_punct_removed'] = df['review_contractions_removed'].apply(remove_punctuation)\n",
    "df.review_punct_removed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYwcG1l0wUz4"
   },
   "source": [
    "# Lower Casing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YOmVpwswUz4"
   },
   "source": [
    "Biscuits, biscuits :  there is no difference in both words but if we keep this as it is, it will be treated as different words which will affect our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "d7XM35EQwUz4",
    "outputId": "ddd2b8cf-785b-4d7c-ba2e-15a1720640a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    this product so far has not disappointed my ch...\n",
       "1    great for beginner or experienced person bough...\n",
       "2    inexpensive tablet for him to use and learn on...\n",
       "3    i have had my fire hd 8 two weeks now and i lo...\n",
       "4    i bought this for my grand daughter when she c...\n",
       "Name: review_lower, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_lower'] = df['review_punct_removed'].apply(str.lower)\n",
    "df.review_lower.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ez3HIkStwUz4"
   },
   "source": [
    "# Installing NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BH_P2UR9wUz4"
   },
   "source": [
    "!pip install nltk \n",
    "conda install -c conda-forge nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DBneCAIuwUz4"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssYZP4UvwUz4"
   },
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0ZE9oUbRwUz4",
    "outputId": "5464fae0-9391-4396-b941-4986813898f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [this, product, so, far, has, not, disappointe...\n",
       "1    [great, for, beginner, or, experienced, person...\n",
       "2    [inexpensive, tablet, for, him, to, use, and, ...\n",
       "3    [i, have, had, my, fire, hd, 8, two, weeks, no...\n",
       "4    [i, bought, this, for, my, grand, daughter, wh...\n",
       "Name: review_tokenized, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df['review_tokenized'] = df['review_lower'].apply(tokenizer.tokenize)\n",
    "df.review_tokenized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Q_gWBWSwUz4"
   },
   "source": [
    "# Removing stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLc7Jq0OwUz5"
   },
   "source": [
    "Common words which are ignored by most search engines because including them increase the size of the index without improving precision or recall\n",
    "For example : i, me, myself, we, our, ours, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pc1kcAwRwUz5"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "c5YiksL4wUz5",
    "outputId": "60b258e9-f49a-41a4-dbd2-fe44c7870277"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [product, far, disappointed, children, love, u...\n",
       "1    [great, beginner, experienced, person, bought,...\n",
       "2    [inexpensive, tablet, use, learn, step, nabi, ...\n",
       "3    [fire, hd, 8, two, weeks, love, tablet, great,...\n",
       "4    [bought, grand, daughter, comes, visit, set, u...\n",
       "Name: review_stop_removed, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_stop_removed'] = df['review_tokenized'].apply(remove_stopwords)\n",
    "df.review_stop_removed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3bEoasVwUz5"
   },
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_qoEvNKwUz5"
   },
   "source": [
    "Normlize the word in its base form/root form\n",
    "For example the words fish, fishes and fishing all stem to fish\n",
    "Result may or may not be root word\n",
    "Common types of Stemming algos: Porter, Lancaster and Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WR0vDtZdwUz5"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luA8ORPSwUz5"
   },
   "outputs": [],
   "source": [
    "def word_stemmer(text):\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in text])\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qk-3c2vrwUz5",
    "outputId": "cf25dc75-b337-470c-84c7-31b334c940c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    product far disappoint children love use like ...\n",
       "1       great beginn experienc person bought gift love\n",
       "2    inexpens tablet use learn step nabi thrill lea...\n",
       "3    fire hd 8 two week love tablet great valuew pr...\n",
       "4    bought grand daughter come visit set user ente...\n",
       "Name: review_stemmed, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_stemmed'] = df['review_stop_removed'].apply(word_stemmer)\n",
    "df.review_stemmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXnt0S-9wUz5"
   },
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-pLCPHKwUz5"
   },
   "source": [
    "Few words like study, studies and studying stems into 'studi', which is not an English word\n",
    "Somehow similar to stemming as it maps several words into one common root\n",
    "Output of Lemmatization is a sproper word\n",
    "For example, a lemmatizer should map gone,going and went into go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppnG9CR0wUz5"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i,\"v\") for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpitjBK0wUz5",
    "outputId": "9a827fb7-2618-49ad-acd0-f34ec75112fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [product, far, disappoint, children, love, use...\n",
       "1    [great, beginner, experience, person, buy, gif...\n",
       "2    [inexpensive, tablet, use, learn, step, nabi, ...\n",
       "3    [fire, hd, 8, two, weeks, love, tablet, great,...\n",
       "4    [buy, grand, daughter, come, visit, set, user,...\n",
       "Name: review_lemmatized, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_lemmatized'] = df['review_stop_removed'].apply(word_lemmatizer)\n",
    "df.review_lemmatized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4l9UVg4OwUz5"
   },
   "source": [
    "[link text](https://)# Pre-processing for Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "executionInfo": {
     "elapsed": 1204,
     "status": "error",
     "timestamp": 1606481643410,
     "user": {
      "displayName": "Mahesh Bhargava",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh04tW-i8LfrW_l0YCY3VGVJJiP5D6JxsWBUOp5yA=s64",
      "userId": "06167394125665952458"
     },
     "user_tz": -330
    },
    "id": "vG_1wIDVwUz5",
    "outputId": "fa3af39d-e778-4b75-c5da-141256a871c6"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ea619d7125e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.xlsx'"
     ]
    }
   ],
   "source": [
    "df=pd.read_excel('data.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxPnEvTFwUz5"
   },
   "source": [
    "# For English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-6929zKwUz5",
    "outputId": "8b5b4e28-0132-4df9-fa3c-c479aa1bd39b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programming in java prof debasis samanta depar...</td>\n",
       "      <td>कम्प्यूटर साइंस इंजीनियरिंग इंडियन इंस्टीट्यूट...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction</td>\n",
       "      <td>परिचय</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first of all i wish like to welcome you all to...</td>\n",
       "      <td>सबसे पहले मैं आप सभी का पाठ्यक्रम में स्वागत क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so this is the first lecture</td>\n",
       "      <td>तो, यह पहला व्याख्यान है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in this first lecture i will try to cover the ...</td>\n",
       "      <td>इस पहले व्याख्यान में मैं जावा प्रोग्रामिंग के...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>so far this translation there are two modes av...</td>\n",
       "      <td>इसलिए, इस अनुवाद में दो मोड उपलब्ध हैं एक कंपा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>so compiler will translate the entire program ...</td>\n",
       "      <td>इसलिए, कंपाइलर एक बार में पूरे कार्यक्रम का अन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>it will basically translate one statement and ...</td>\n",
       "      <td>यह मूल रूप से एक स्टेटमेंट का अनुवाद करेगा और ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>so the exhibition will hold or it will just by...</td>\n",
       "      <td>इसलिए, प्रदर्शनी आयोजित की जाएगी या यह उस बयान...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>but on the other hand compiler will check that...</td>\n",
       "      <td>लेकिन दूसरी तरफ संकलक यह जांच करेगा कि प्रोग्र...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  src  \\\n",
       "0   programming in java prof debasis samanta depar...   \n",
       "1                                        introduction   \n",
       "2   first of all i wish like to welcome you all to...   \n",
       "3                        so this is the first lecture   \n",
       "4   in this first lecture i will try to cover the ...   \n",
       "..                                                ...   \n",
       "95  so far this translation there are two modes av...   \n",
       "96  so compiler will translate the entire program ...   \n",
       "97  it will basically translate one statement and ...   \n",
       "98  so the exhibition will hold or it will just by...   \n",
       "99  but on the other hand compiler will check that...   \n",
       "\n",
       "                                                  tgt  \n",
       "0   कम्प्यूटर साइंस इंजीनियरिंग इंडियन इंस्टीट्यूट...  \n",
       "1                                               परिचय  \n",
       "2   सबसे पहले मैं आप सभी का पाठ्यक्रम में स्वागत क...  \n",
       "3                           तो, यह पहला व्याख्यान है।  \n",
       "4   इस पहले व्याख्यान में मैं जावा प्रोग्रामिंग के...  \n",
       "..                                                ...  \n",
       "95  इसलिए, इस अनुवाद में दो मोड उपलब्ध हैं एक कंपा...  \n",
       "96  इसलिए, कंपाइलर एक बार में पूरे कार्यक्रम का अन...  \n",
       "97  यह मूल रूप से एक स्टेटमेंट का अनुवाद करेगा और ...  \n",
       "98  इसलिए, प्रदर्शनी आयोजित की जाएगी या यह उस बयान...  \n",
       "99  लेकिन दूसरी तरफ संकलक यह जांच करेगा कि प्रोग्र...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['src']=df['src'].apply(remove_html)\n",
    "df['src']=df['src'].apply(replace_contractions)\n",
    "df['src']=df['src'].apply(remove_punctuation)\n",
    "df['src']=df['src'].apply(str.lower)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMym6mWIwUz6"
   },
   "source": [
    "# For Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMNKZ6AnwUz6",
    "outputId": "321a1488-ae2d-4aeb-a56e-671cb3d9be01"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programming in java prof debasis samanta depar...</td>\n",
       "      <td>कम्प्यूटर साइंस इंजीनियरिंग इंडियन इंस्टीट्यूट...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction</td>\n",
       "      <td>परिचय</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first of all i wish like to welcome you all to...</td>\n",
       "      <td>सबसे पहले मैं आप सभी का पाठ्यक्रम में स्वागत क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so this is the first lecture</td>\n",
       "      <td>तो यह पहला व्याख्यान है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in this first lecture i will try to cover the ...</td>\n",
       "      <td>इस पहले व्याख्यान में मैं जावा प्रोग्रामिंग के...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>so far this translation there are two modes av...</td>\n",
       "      <td>इसलिए इस अनुवाद में दो मोड उपलब्ध हैं एक कंपाइ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>so compiler will translate the entire program ...</td>\n",
       "      <td>इसलिए कंपाइलर एक बार में पूरे कार्यक्रम का अनु...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>it will basically translate one statement and ...</td>\n",
       "      <td>यह मूल रूप से एक स्टेटमेंट का अनुवाद करेगा और ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>so the exhibition will hold or it will just by...</td>\n",
       "      <td>इसलिए प्रदर्शनी आयोजित की जाएगी या यह उस बयान ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>but on the other hand compiler will check that...</td>\n",
       "      <td>लेकिन दूसरी तरफ संकलक यह जांच करेगा कि प्रोग्र...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  src  \\\n",
       "0   programming in java prof debasis samanta depar...   \n",
       "1                                        introduction   \n",
       "2   first of all i wish like to welcome you all to...   \n",
       "3                        so this is the first lecture   \n",
       "4   in this first lecture i will try to cover the ...   \n",
       "..                                                ...   \n",
       "95  so far this translation there are two modes av...   \n",
       "96  so compiler will translate the entire program ...   \n",
       "97  it will basically translate one statement and ...   \n",
       "98  so the exhibition will hold or it will just by...   \n",
       "99  but on the other hand compiler will check that...   \n",
       "\n",
       "                                                  tgt  \n",
       "0   कम्प्यूटर साइंस इंजीनियरिंग इंडियन इंस्टीट्यूट...  \n",
       "1                                               परिचय  \n",
       "2   सबसे पहले मैं आप सभी का पाठ्यक्रम में स्वागत क...  \n",
       "3                             तो यह पहला व्याख्यान है  \n",
       "4   इस पहले व्याख्यान में मैं जावा प्रोग्रामिंग के...  \n",
       "..                                                ...  \n",
       "95  इसलिए इस अनुवाद में दो मोड उपलब्ध हैं एक कंपाइ...  \n",
       "96  इसलिए कंपाइलर एक बार में पूरे कार्यक्रम का अनु...  \n",
       "97  यह मूल रूप से एक स्टेटमेंट का अनुवाद करेगा और ...  \n",
       "98  इसलिए प्रदर्शनी आयोजित की जाएगी या यह उस बयान ...  \n",
       "99  लेकिन दूसरी तरफ संकलक यह जांच करेगा कि प्रोग्र...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tgt']=df['tgt'].apply(remove_html)\n",
    "df['tgt']=df['tgt'].apply(remove_punctuation)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4c_UHm9wUz6"
   },
   "outputs": [],
   "source": [
    "df.to_excel('preProcessed.xlsx')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP-PP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
